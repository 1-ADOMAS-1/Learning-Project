{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "HkEkXND-KabN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import libraries"
      ],
      "metadata": {
        "id": "YvZaDWfGKdia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as v2\n",
        "\n",
        "from torch.utils.data import BatchSampler, SequentialSampler\n",
        "from torchvision import models\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "RcLxpewpm0yF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class RNN\n"
      ],
      "metadata": {
        "id": "V3icsoOUKnJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRNN(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "    self.hidden_size = 64\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "\n",
        "    self.rnn = nn.RNN(self.in_features, self.hidden_size, batch_first=True)\n",
        "    self.out = nn.Linear(self.hidden_size, self.out_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, h = self.rnn(x)\n",
        "    y = self.out(h)\n",
        "    return y"
      ],
      "metadata": {
        "id": "mbTU5bpRn3_4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Dataset\n"
      ],
      "metadata": {
        "id": "YwhtpXm6KpjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class charsDataset(data.Dataset):\n",
        "  def __init__(self, path, prev_chars=3):\n",
        "    self.prev_chars = prev_chars\n",
        "\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "      self.text = f.read()\n",
        "      self.text = self.text.replace('\\ufeff', '')\n",
        "      self.text = re.sub(f'[^А-яA-z0-9.,?;: ]', '', self.text)\n",
        "\n",
        "    self.text = self.text.lower()\n",
        "    self.alphabet = set(self.text)\n",
        "    self.int_to_alpha = dict(enumerate(sorted(self.alphabet)))\n",
        "    self.alpha_to_int = {v: k for k, v in self.int_to_alpha.items()}\n",
        "    self.num_characters = len(self.alphabet)\n",
        "    self.onehots = torch.eye(self.num_characters)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    _data = torch.vstack([self.onehots[self.alpha_to_int[self.text[x]]] for x in range(item, item + self.prev_chars)])\n",
        "    ch = self.text[item + self.prev_chars]\n",
        "    t = self.alpha_to_int[ch]\n",
        "    return _data, t\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text) - 1 - self.prev_chars"
      ],
      "metadata": {
        "id": "WrC0wXiOoyVB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "SnJw0_27KwUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch=8\n",
        "d_train = charsDataset('/content/train_data_true', prev_chars=10)\n",
        "train_loader = data.DataLoader(d_train, batch_size=batch, shuffle=True)"
      ],
      "metadata": {
        "id": "dSEJHSeGAODY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextRNN(d_train.num_characters, d_train.num_characters)"
      ],
      "metadata": {
        "id": "MLdoVOBYBPyQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
        "loss_f = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "PmkE5BB0Ba8n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch=100\n",
        "model.train()\n",
        "\n",
        "for _e in range(epoch):\n",
        "  loss_mean = 0\n",
        "  lm_count = 0\n",
        "\n",
        "  train_tqdm = tqdm(train_loader, leave=False)\n",
        "  for x_train, y_train in train_tqdm:\n",
        "    pred = model(x_train).squeeze(0)\n",
        "    loss = loss_f(pred, y_train.long())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    lm_count+=1\n",
        "    loss_mean = 1/lm_count * loss.item() + (1-1/lm_count)*loss_mean\n",
        "    train_tqdm.set_description(f'[epoch ({_e+1}/{epoch}], loss_mean: {loss_mean:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH72DygnBqlI",
        "outputId": "a57b6874-cd5d-42de-d7cc-61037bf2f68b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st = model.state_dict()\n",
        "torch.save(st, 'model_rnn_1.tar')"
      ],
      "metadata": {
        "id": "h1PAl729C-iF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "Aj7KNCCNK2XK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "predict='Мой дядя самый'.lower()\n",
        "total=40\n",
        "\n",
        "for _ in range(total):\n",
        "  _data = torch.vstack([d_train.onehots[d_train.alpha_to_int[predict[-x]]] for x in range(d_train.prev_chars, 0, -1)])\n",
        "  p = model(_data.unsqueeze(0)).squeeze(0)\n",
        "  indx = torch.argmax(p, dim=1)\n",
        "  predict += d_train.int_to_alpha[indx.item()]\n",
        "\n",
        "print(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nccayvgFQ1h",
        "outputId": "4b4316ca-ad64-4d4b-8e1d-a29fc14bffea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мой дядя самыйся это ны что дыто нечем прдоль у осчаст\n"
          ]
        }
      ]
    }
  ]
}